---
title: "Scratch Work"
author: "Simon Dovan Nguyen"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float: yes
    toc_collapsed: yes
    theme: lumen
    css: assets/styles.css
---

# Set Up

## Notes

## Libr.

```{r message=FALSE, warning=FALSE}
library(MASS)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(class)
library(glmnet)
```

## Rm. Var.

```{r}
rm(list=ls())
```

## Functions

```{r}
dir = "/Users/simondn/Documents/RashomonActiveLearning/"
source(paste0(dir,"functions/BreakingTiesSelector.R"))
source(paste0(dir,"functions/GenerateData.R"))
source(paste0(dir,"functions/GenerateData2.R"))
source(paste0(dir,"functions/RandomStart.R"))
source(paste0(dir,"functions/RandomSelector.R"))
source(paste0(dir,"functions/SelectorSimulationFunc.R"))
source(paste0(dir,"functions/StoppingCriteria.R"))
```

# Generate Data

## Data

```{r}
set.seed(3)
### Input ###
N = 1000
K = 2
NClass = 2
# ClassProportion = c(1/3,2/3)
ClassProportion = rep(1/NClass, NClass)
MeanMatrix = rep(0,K)
CorrVal = 0.0
```

```{r}
### Data ###
DGPResults = GenerateDataFunc(N, K, NClass, ClassProportion, MeanMatrix, CorrVal)
# DGPResults = GenerateDataFunc2(N, K, NClass, ClassProportion, MeanMatrix, CorrVal)
dat = DGPResults$dat
YStar = DGPResults$YStar
TrueBetas = DGPResults$TrueBetas
Noise = DGPResults$noise
# rm(DGPResults)
```

## Visualize

```{r}
HistogramY = ggplot() +
  geom_histogram(mapping = aes(x = YStar, color = as.factor(dat$Y)))
  # geom_point(mapping = aes(x = Y, y = 0, color = as.factor(Label))) 

ScatterPlotY = ggplot() +
  geom_point(mapping = aes(x = YStar, y = 0, color = as.factor(dat$Y)))


ScatterPlotX1X2 = ggplot(data = dat) +
  geom_point(mapping = aes(x = X1, y = X2, color = as.factor(Y))) 

ScatterPlotY
HistogramY
ScatterPlotX1X2
```

# Model

## Logistic
```{r}
LogModel = glm(Y ~ ., 
                   data = dat[, setdiff(names(dat), c("ID"))],
                   family = "binomial")
LogPredicted = 1*(predict(LogModel, newdata = dat, type = "response")>0.5)+1
LogPredictedProbabilities = predict(LogModel,
                                    newdata = dat,
                                    type = "response")
mean(LogPredicted != dat$Y)
```


## KNN
```{r}
KNNModel = knn(train = dat[, setdiff(names(dat), c("Y", "ID"))],
               test =  dat[, setdiff(names(dat), c("Y", "ID"))],
               cl = dat[,"Y"],
               k = 5)
mean(KNNModel != dat[,"Y"])
```

## Multinom
```{r}
library(nnet)
MultinomModel = multinom(Y ~ .,
                    data = dat,
                    trace = FALSE)

MultinomModelPredicted = predict(MultinomModel,
                                 newdata = dat)
MultinomModelPredictedProbabilities = predict(MultinomModel,
                                              newdata = dat,
                                              type = "prob")
mean(MultinomModelPredicted != dat$Y)
```

## LASSO

```{r}
# Model #
# X = as.matrix(dat[,c(3,4)])
# Y = as.factor(dat[,2])
# 
# LASSO_Regression = glmnet(x = X, 
#                           y = Y,
#                           alpha = 1,
#                           family = "binomial")
# LASSO_Lambda = min(LASSO_Regression$lambda)
# 
# # Training Prediction #
# LASSO_Training_Prediction = predict(LASSO_Regression, 
#                                     newx = X, 
#                                     s = LASSO_Lambda,
#                                     type = "response")
# hist(LASSO_Training_Prediction)
# 
# mean((LASSOTrainingPrediction+1) != dat$Y)

```


```{r}
### Lambda ###
# CVLasso = cv.glmnet(x= as.matrix(dat[, setdiff(names(dat), c("ID", "Y"))]),
#                     y= as.factor(as.matrix(dat[, "Y"])),
#                     alpha = 1,
#                     family = "binomial")
# LASSOLambda = CVLasso$lambda.min
# 
# # Training Prediction #
# LASSOTrainingPrediction = glmnet(x=as.matrix(dat[, setdiff(names(dat), c("ID", "Y"))]),
#                                  y= as.factor(as.matrix(dat[, "Y"])),
#                                  alpha = 1,
#                                  lambda = LASSOLambda,
#                                  family = "binomial")
# 
# LASSOTrainingPrediction = predict(LASSOTrainingPrediction,
#                                   newx = as.matrix(dat[, setdiff(names(dat), c("ID", "Y"))]),
#                                   s = LASSOLambda,
#                                   type = "response")
# 
# LASSOTrainingPrediction =  ifelse(LASSOTrainingPrediction > 0.5,1,0)
# 
# mean((LASSOTrainingPrediction+1) != dat$Y)
```

## Random Selection

```{r}
RandomStart = RandomStartFunc(InitialN=1, dat=dat)
TrainingSet = RandomStart$TrainingSet
CandidateSet = RandomStart$CandidateSet
```

## Simulation

```{r}
dat = dat
TailN = 50
ErrorThreshold = 0.4
VarThreshold = .1
TrainingSet = TrainingSet
CandidateSet = CandidateSet
SelectorN = 1
```


```{r}
SelectorSimulationFunc(dat = dat,
                       TailN = TailN,
                       ErrorThreshold = ErrorThreshold,
                       VarThreshold = VarThreshold,
                       TrainingSet = TrainingSet,
                       CandidateSet = CandidateSet,
                       SelectorType = "Random",
                       SelectorN = 1) -> SimResultsRandom

SelectorSimulationFunc(dat = dat,
                       TailN = TailN,
                       ErrorThreshold = ErrorThreshold,
                       VarThreshold = VarThreshold,
                       TrainingSet = TrainingSet,
                       CandidateSet = CandidateSet,
                       SelectorType = "BreakingTies",
                       SelectorN = 1) -> SimResultsBreakingTies
```
```{r}
SimResultsRandom$ErrorScatterPlot
SimResultsBreakingTies$ErrorScatterPlot
```
```{r}
LineTypes = c("Random" = "dashed",
         "BreakingTies" = "solid")

ErrorScatterPlot = ggplot() +
    geom_line(mapping = aes(x = 1:length(SimResultsRandom$Error), 
                            y = SimResultsRandom$Error,
                            linetype = "Random")) + 
    geom_line(mapping = aes(x = 1:length(SimResultsBreakingTies$Error), 
                            y = SimResultsBreakingTies$Error,
                            linetype = "BreakingTies")) + 
    geom_vline(xintercept = SimResultsRandom$StopIter, 
               color = "red",
               linetype = "dashed") + 
    geom_vline(xintercept = SimResultsBreakingTies$StopIter, 
               color = "red",
               linetype = "solid") +
# Aesthetics
    xlab("Iterations") +
    ylab("Error") +
    ggtitle("Simulation by Error") +
    theme(plot.title = element_text(size = 15, hjust = 0.5)) +
  xlim(0,200)

ErrorScatterPlot

```